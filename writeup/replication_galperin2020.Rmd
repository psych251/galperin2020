---
title: Replication Report for Study 2 by Galperin, Hahl, Stering, & Guo (2020, Administrative
  Science Quarterly)
author: "Jiwon Byun (jwbyun@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '3'
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/jbyun/Dropbox/2021 Fall/PSYCH 251/galperin2020")
```




## Introduction

Employers' selection of job applicants is an important labor market proesses for both employers and individuals. For organizations, access to high-quality workers is a source of competitive advantage. For individuals, access to certain jobs at certain timing can have a large impact on one's career trajectories. Job signaling is the most fundamental and important aspect of selection processes in labor market. Information asymmetries between employers and job applicants provide challenges for both ends. \
Most studies have focused on job signaling and applicant capabilities when trying to understand selection processes in labor markets. On the other hand, increasing number of studies suggest that selection decisions are affected not only by perceptions of applicantss' capability but also by perceptions of applicants' commitment to the organization. \
While previous literature investigated both the effect of perceptions of applicants' capability and the effect of perceptions of applicants' commitment on the likelihood of a candidate's being selected for a job, the relationship between the two dimensions had been understudied. In an attempt to shed light on such a gap in the literature, Galperin, Hahl, Sterling, and Guo (Gelperin et al. henceforth) conducted a series of online field experiments and published an article in ASQ in the year of 2020. (For reference, see `Links` section in the below.) \
Galperin et al. (2020) suggested that signals that influence perceptions of capability in labor markets may have discernable effects of the perceptions of a candidate's commitment, which also affects the likelihood of the candidate's being selected for the job. The paper included four studies, three of which were online field experiments. In this study, I plan to replicate Study 2. \
\

### Justification for choice of study

In the original paper, the authors conducted a direct test of the effect of applicants' commitment and high-capability rejection. \
Study 2 was conducted to directly manipulated perceived commitment of an applicant to complement one of the other studies where they could not directly manipulate commitment. This is important because the main contribution of the study is suggested (and proved) mediation effect of commitment on likelihood of a job offer. \
\


### Anticipated challenges

I anticipate two challenges while attempting to replicate the results. \
First, I may run into sample issue. This study is about job signals and hiring managers' decision making in making job offers. Hence, it is important that I only have hiring managers (defined by someone with experiences as a hiring manager) in the sample. Since I have to rely on Prolifics to do the sampling, less appropriate sample might be acquired in the end. Similar issue applies to random assignment of participants. \
Second, survey design might be difficult. The main part of this replication study is manipulating commitment of a job applicant. Since commitment could mean different things both conceptually and practically, it is essential that I manipulate the main concepts elaborately. To overcome this challenge, I plan to reach out to original authors and try to acquire survey items that they used for the original study. \
\


### Links

* Project repository (on Github): [Link to project repository](https://github.com/psych251/galperin2020.git)
* Original paper (as hosted in your repo): [Link to original paper](https://github.com/psych251/galperin2020/blob/1176bad85fcced90757aa9a19be77c14f0b70a5f/original_paper/galperin_et_al_2020.pdf)


\


## Methods


### Description of the steps required to replicate the results

To replicate the results of Study 2, I plan to run the same online experiment on Prolific. Prior to running the main study, I plan to run two pilot studies. The first pilot study will involve non-naive participants, whereas the second pilot study will have naive participants on MTurk. \
For the main study, participants will be recruited to fill out a "survey for hiring managers" through Prolific in October-November 2021. \
The study will have the same structure as that of the original study: 2 by 2 between-subjects design. Participants will be randomly assigned to one of the four conditions. (2 capability conditions X 2 commitment conditions) They will be given the same stimuli as the original study. \
I plan to conduct a manipulation check for both candidate's perceived capability and perceived commitment by combining the questionnaires included in the survey. \
With the data acquired from the survey experiment, I plan to conduct two t-tests to replicate the key results of Study 2. As an exploratory analysis, I plan to conduct a two-way ANOVA to examine the interaction effects. \
\



### Power Analysis

The original study had a sample size of 212. For the first t-test (neutral commitment condition), the statistics were: `t = 3.66`, `p < 0.001`. For the second t-test (high commitment condition), the results were: `t = -3.34`, `p = 0.001`.

Since I have two t-test for the study, I chose the t-test with smaller t value and used the study for the power analysis, which is the second t-test with `t = -3.34`. Then I did a calculation assuming a balanced cell size.

Results of the effect size calculation for the second t-test (calculated by using mean and s.d.) were as follows: `Cohen's d = 0.6554`,  `effect-size r = 0.3114`. I conducted the effect size calculation using the t-value and degrees of freedom as well and obtained very similar results.

Based on the effect size, I conducted a power analysis. Results for the power analysis for 80%, 90%, 95% power (for the second t-test) are as follows:

* 80% power: 76
* 90% power: 100
* 95% power: 124

Since the original work did have two t-tests, I needed to take the results and multiply by 2 to get the results for power analysis for the whole study. Therefore, the final results for the power analysis were as follows:

* 80% power: 152
* 90% power: 200
* 95% power: 248

The sample size for the 80% power (based on the original effect of the second t-test) was 152. I could not have 152 participants due to some constraints (mainly financial.) The original study paid the participants high compensation (`$6.00`) for this cognitively engaging study, I want to provide a reasonable amount of compensation to each participant. Considering the approximate time needed to complete the study and the hourly pay, I decided to pay `$2.00` each. My budget is limited at about `$400.00` for the study, so I decided have a sample size of `150`.
\
\


### Planned Sample

The sample consists of `150` participants recruited from Prolific. In order to participate in the study, individuals should have an experience hiring people for the organization because this study addresses job decision making processes of hiring managers in the labor market. They also have to be residents of U.S. because job candidate's qualification and evaluations depend on the nuiances in the labor market, which may be different across different regions.
\

### Materials

The survey experiment materials were coded in Qualtrics. Participants recuited on Prolific could click on the link to the survey on Qualtrics. Participants were randomly assigned to `2 capability conditions` that involved two different job candidate resumes. Participants were also randomly assigned to `2 commitment conditions` given by information from HR department. The procedure for the study is described below.


#### Link:

* Survey material: [Link to the survey](https://stanforduniversity.qualtrics.com/jfe/preview/SV_3egYJH4CkorsKzk?Q_CHL=preview&Q_SurveyVersionID=current)

All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article.
\
* `What do we need to put here? (Jiwon)`


### Procedure 

"The procedure for Study 2 was very similar to that for Study 1. We used the same job candidate profiles as in Study 1, but instead of evaluating both candidates, participants viewed only one profile and were asked to evaluate only that candidate applying to a 'corporate finance position in a medium-size health care company.' To verify that participants understood the directions, we asked them a series of attention-check questions. If they answered incorrectly, the context was repeated to them as a reinforcement.

One additional difference between Study 1 and Study 2 was that in this experiment, participants were told that their job as 'line manager' meant they 'should not concern themselves with negotiating the offer, but should only consider this candidate's potential performance on the job.' This was repeated before the participant was asked about his or her likelihood of giving the candidate an offer. We also asked participants to rate from 1 (low) to 7 (high) how concerned they were about the candidate accepting the job. There was no difference across conditions in this measure, and results presented below are robust to controlling for this measure. This indicates that participants behaved as intended and focused on post-hire commitment rather than concerns about the candidate’s acceptance of a job offer.

Participants were randomly assigned to view either the extremely highcapability candidate or the moderately high-capability candidate, who were presented in the same way as they were in Study 1. Next, participants were randomly assigned to one of two commitment-information conditions: neutral or high. All participants were told, 'As part of the application process, the candidate completed an assessment delivered by your firm’s HR department,' that the candidate scored a 75 on the assessment, and that 'candidates that have scored at least 60 points have skills that match the requirements of the job.' In the neutral-commitment condition, nothing was mentioned about the assessment’s relationship with commitment. Participants were told that 'this assessment was able to predict the candidate's ability to do the job in your firm.' In contrast, participants randomly assigned to the high-commitment condition were told that 'this assessment was able to predict the candidate's likely commitment to your organization (e.g., likelihood to stay with your firm, be motivated and work well with others).' This procedure resulted in a 2 (extremely high capability/moderately high capability) by 2 (high commitment/neutral commitment) between-subject design.

Participants were then asked about their likelihood of giving the candidate a job offer based on the same scale used in Study 1. This variable served as the dependent variable." (Galperin et al., 2020)

For this replication, the original work's procedure (described in the quotation above) was followed precisely.

\




### Analysis Plan

Confirmatory statistical analysis is going to involve two t-tests, following the methods used in the original work. I run a t-test for High-commitment conditions, and another t-test for Neutral-commitment conditions. By doing so, I can test differential effects of extremely high capability on likelihood of getting an offer for different commitment conditions.

I plan to conduct the same manipulation check analyses of those from original work. There are 4 measures for capability and 4 measures for commitment. As the original authors did, I will average the ratings for capability and commitment (separately for each manipulation) and created a perceived capability measure and a perceived commitment measure. Then I will examine Cronbach's alpha value and conduct t-tests across different treatment groups.

Since the original work aims to explore the interactional effects of capability and commitment on a candidate's likelihood of getting an offer, I plan to conduct a two-wawy ANOVA as an exploratogy analysis. Two-way ANOVA can be a good statitical model since I am trying to examine the interation effect of candidate's capability and commitment (Capability X Commitment) on the likelihood of receiving an offer. By using the two-way factorial design, I can effectively examine the potential interaction effect between Capability and Commitment.



#### Pilot B and Sampling

While the first pilot (Pilot A) went smoothly, I had some issues with Pilot B. So I had to run Pilot B three times to identify the appropriate strategy to run the study on Prolific. Three pilots were conducted on Prolific between November 12, 2021 and November 14, 2021. All three pilots were conducted with sample size of N=4. The participants were recruited on Prolific. They had to have hiring experience to be eligible for the study.
The original plan was to recruit participants internationally on Prolific. After the first Pilot B, I realized that this sampling strategy was not appropriate. Even with the language filter, (fluency in English) international participants were taking too long to complete the study. The median value for the duration of the stuay was approximately 24 minutes for a 10-minute study.
Therefore I conducted the second Pilot B with different sampling strategy. I added another filter so that only residents of U.S. can participate in the study. I also deleted all the open-ended questions from the survey. After running the second pilot, I could see that the problem was more about participants' country of residence than having open-ended questions in the survey.
Hence, I ran the third Pilot B with the original survey design. The sampling strategy was the same as the second pilot (individuals with hiring experience who live in the U.S., fluent in English). The third pilot ran without any problem and I was able to collect data.
\





### Differences from Original Study (EDITING)

The most important difference would be that I will be using a different sample. While the original work recruited participants through Qualtrics panel, I will recruit participants through Prolific. While I do not foresee any systematic differences between two platforms, some substantial differences may exist when filtering for the target participants. This may cause differences between the sample of this study and that of original paper. \
I acknowledge that any unforeseen issues are the sole responsiblitity of mine. \

```
DIFFERENCES BETWEEN SAMPLES ARE VERY IMPORTANT HERE. So I probably need to elaborate on how and why sampling is important and how I might end up with a very different sample.
```




### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.




## Results (EDITING)


### Data preparation

First, when the study is done, download data from Qualtrics using `qualtRics` package. (Other than `qualtRics` package, load other essential packages for data analysis and visualization, such as: `tidyverse`, `knitr`, `ggplot2`, `stats`, and etc.) \
Second, clean the data. Check for missing values and exclude observations with missing values. If needed, conduct data manipulation. Clean and manipulate data so that I have a clean tidy data. \
Third, conduct descriptive analyses. Before running the main statistical models, run some descriptive analysis and show the descriptives as needed. \
Fourth, conduct main statistical analysis. Present the findings in a table. \
Fifth, do some data visualization so that the readers can view the results easily. \
Lastly, if needed, run some additional analysis. (Check for homoscedasticity, conduct robustness checks, more explaratory analysis, etc.) \
\



#### Load Relevant Libraries and Functions

```{r, echo = TRUE}
library(qualtRics)
library(tidyverse)
library(knitr)
library(psych)
library(haven)
library(readxl)
library(Rmisc)
library(purrr)
library(broom)
library(car)
library(psych)
library(rstatix)

```

\

#### Import data

```{r, echo = TRUE}
# load survey
#data_fin_raw <- fetch_survey(surveyID = "SV_82M7ojjd1rLcGPA", force_request = T)
```

```{r, echo = TRUE}
# save data
#write_csv(data_fin_raw, "/Users/jbyun/Dropbox/2021 Fall/PSYCH 251/galperin2020/data/data_fin_raw.csv")
```

```{r, echo = TRUE}
# load data from csv
data_fin_raw <- read_csv("/Users/jbyun/Dropbox/2021 Fall/PSYCH 251/galperin2020/data/data_fin_raw.csv")
```

\

#### Data exclusion / filtering

```{r}
data_raw <- data_fin_raw
```

```{r}
# exclude participants who did not meet the eligibility requirement
# or those who might have been included by accident (i.e. myself) who did not go through Prolific
# 6 obs dropped
data <- data_raw %>%
  filter(hiringexperience == "Yes") %>%
  filter(!is.na(prolific_id))

describe(data)

# add id column
data <- tibble::rowid_to_column(data, "id")
```




```{r}
### Clean data (first step)

# select needed columns
data <- data %>%
  select(c('ResponseId', 'id', 'companychk', 'candatchk', 'Location', 'interview', 'offer', 'opencncrn', 'openresolv', 'referral', 'competent', 'productive', 'skilled', 'finexp', 'committed', 'commit_ind', 'extrhrs', 'teamwork', 'stay', 'flightrsk', 'oe_qual', 'oe_comm', 'oe_interview', 'oe_offer', 'oe_referral', 'ethnicity', 'race_1', 'race_2', 'race_3', 'race_4', 'race_5', 'race_6', 'race_7', 'race_8', 'race_8_TEXT', 'gender', 'Age', 'educ', 'workexperience', 'Profile_DO_high_overqual_profil', 'Profile_DO_low_overqual_profile', 'CommitmentManipulation_DO_highcommitment_HR', 'CommitmentManipulation_DO_neutralcommitment_HR'))


# data manipulation - scores

# likelihood of getting an interview (score)
data <- data %>%
  mutate(interview_score = ifelse(interview == "Very Unlikely", 1,
                                  ifelse(interview == "Unlikely", 2,
                                         ifelse(interview == "Somewhat Unlikely", 3,
                                                ifelse(interview == "Undecided", 4,
                                                       ifelse(interview == "Somewhat Likely", 5,
                                                              ifelse(interview == "Likely", 6, 
                                                                     ifelse(interview == "Very Likely", 7, NA))))))))

# likelihood of getting an offer (score)
data <- data %>%
  mutate(offer_score = ifelse(offer == "Very Unlikely", 1, 
                              ifelse(offer == "Unlikely", 2, 
                                     ifelse(offer == "Somewhat Unlikely", 3, 
                                            ifelse(offer == "Undecided", 4, 
                                                   ifelse(offer == "Somewhat Likely", 5, 
                                                          ifelse(offer == "Likely", 6,  
                                                                 ifelse(offer == "Very Likely", 7, NA))))))))


# referral or not
data <- data %>%
  mutate(refer = ifelse(referral == "Yes", 1, 0)) %>%
  mutate(refer = as.factor(refer))


### Manipulation checks

# competent
data <- data %>%
  mutate(competent_score = ifelse(competent == "Strongly disagree", 1, 
                                  ifelse(competent == "Disagree", 2, 
                                         ifelse(competent == "Somewhat disagree", 3, 
                                                ifelse(competent == "Neither agree nor disagree", 4, 
                                                       ifelse(competent == "Somewhat agree", 5, 
                                                              ifelse(competent == "Agree", 6, 
                                                                     ifelse(competent == "Strongly agree", 7, NA))))))))


# productive
data <- data %>%
  mutate(productive_score = ifelse(productive == "Strongly disagree", 1, 
                                   ifelse(productive == "Disagree", 2, 
                                          ifelse(productive == "Somewhat disagree", 3, 
                                                 ifelse(productive == "Neither agree nor disagree", 4, 
                                                        ifelse(productive == "Somewhat agree", 5, 
                                                               ifelse(productive == "Agree", 6,
                                                                      ifelse(productive == "Strongly agree", 7, NA))))))))

# skilled
data <- data %>%
  mutate(skilled_score = ifelse(skilled == "Strongly disagree", 1,
                                ifelse(skilled == "Disagree", 2,
                                       ifelse(skilled == "Somewhat disagree", 3,
                                              ifelse(skilled == "Neither agree nor disagree", 4,
                                                     ifelse(skilled == "Somewhat agree", 5,
                                                            ifelse(skilled == "Agree", 6,
                                                                   ifelse(skilled == "Strongly agree", 7, NA))))))))

# finexp
data <- data %>%
  mutate(finexp_score = ifelse(finexp == "Strongly disagree", 1,
                               ifelse(finexp == "Disagree", 2,
                                      ifelse(finexp == "Somewhat disagree", 3,
                                             ifelse(finexp == "Neither agree nor disagree", 4,
                                                    ifelse(finexp == "Somewhat agree", 5,
                                                           ifelse(finexp == "Agree", 6,
                                                                  ifelse(finexp == "Strongly agree", 7, NA))))))))

# committed
data <- data %>%
  mutate(commit_score = ifelse(committed == "Highly uncommitted", 1,
                               ifelse(committed == "Uncommitted", 2,
                                      ifelse(committed == "Somewhat uncommitted", 3,
                                             ifelse(committed == "Neither committed nor uncommitted", 4,
                                                    ifelse(committed == "Somewhat committed", 5,
                                                           ifelse(committed == "Committed", 6,
                                                                  ifelse(committed == "Highly committed", 7, NA))))))))

# commit_ind
data <- data %>%
  mutate(commit_ind_score = ifelse(commit_ind == "Highly uncommitted", 1,
                                   ifelse(commit_ind == "Uncommitted", 2,
                                          ifelse(commit_ind == "Somewhat uncommitted", 3,
                                                 ifelse(commit_ind == "Neither committed nor uncommitted", 4,
                                                        ifelse(commit_ind == "Somewhat committed", 5,
                                                               ifelse(commit_ind == "Committed", 6,
                                                                      ifelse(commit_ind == "Highly committed", 7, NA))))))))



# extra hours score
data <- data %>%
  mutate(extrhrs_score = ifelse(extrhrs == "Very unlikely", 1,
                                ifelse(extrhrs == "Unlikely", 2,
                                       ifelse(extrhrs == "Somewhat unlikely", 3,
                                              ifelse(extrhrs == "Neither likely nor unlikely", 4,
                                                     ifelse(extrhrs == "Somewhat likely", 5,
                                                            ifelse(extrhrs == "Likely", 6,
                                                                   ifelse(extrhrs == "Very likely", 7, NA))))))))

# teamwork score
data <- data %>%
  mutate(teamwork_score = ifelse(teamwork == "Very Unlikely", 1, 
                                 ifelse(teamwork == "Unlikely", 2, 
                                        ifelse(teamwork == "Somewhat unlikely", 3, 
                                               ifelse(teamwork == "Neither likely nor unlikely", 4, 
                                                      ifelse(teamwork == "Somewhat likely", 5, 
                                                             ifelse(teamwork == "Likely", 6, 
                                                                    ifelse(teamwork == "Very likely", 7, NA))))))))



# likelihood of staying score
data <- data %>%
  mutate(stay_score = ifelse(stay == "Less than 1 year", 1,
                             ifelse(stay == "1-2 years", 2,
                                    ifelse(stay == "2-3 years", 3,
                                           ifelse(stay == "3-4 years", 4,
                                                  ifelse(stay == "4-5 years", 5,
                                                         ifelse(stay == "5-6 years", 6,
                                                                ifelse(stay == "Greater than 6 years", 7, NA))))))))





# flight risk score (flightrsk)
data <- data %>%
  mutate(flight_score = ifelse(flightrsk == "Very unlikely", 1, 
                               ifelse(flightrsk == "Unlikely", 2,
                                      ifelse(flightrsk == "Somewhat unlikely", 3,
                                             ifelse(flightrsk == "Neither likely nor unlikely", 4, 
                                                    ifelse(flightrsk == "Somewhat likely", 5,
                                                           ifelse(flightrsk == "Likely", 6,
                                                                  ifelse(flightrsk == "Very likely", 7, NA))))))))

```

```{r}
### Data cleaning continuted - demographic information

#summary(as.factor(data$race_1))
#summary(as.factor(data$race_2))
#summary(as.factor(data$race_3))
#summary(as.factor(data$race_4))
#summary(as.factor(data$race_5))
##summary(as.factor(data$race_6))
#summary(as.factor(data$race_7))
##summary(as.factor(data$race_8))
##summary(as.factor(data$race_8_TEXT))


# ethnicity
data <- data %>%
  mutate(ethnic_hispanic = ifelse(is.na(ethnicity), 0, ifelse(ethnicity == "Hispanic", 1, 0)))

# race
data <- data %>%
  mutate(White = ifelse(!is.na(race_1), 1, 0)) %>%
  mutate(Black = ifelse(!is.na(race_2), 1, 0)) %>%
  mutate(Hispanic = ifelse(!is.na(race_3), 1, 0)) %>%
  mutate(Asian = ifelse(!is.na(race_4), 1, 0)) %>%
  mutate(Native = ifelse(!is.na(race_5), 1, 0)) %>%
  mutate(Decline = ifelse(!is.na(race_6), 1, 0))

# variables with no obs dropped

# gender
data <- data %>%
  mutate(gender = as.factor(gender))

# education
data <- data %>%
  mutate(educ = as.factor(educ))


summary(data$educ)

# add education level (ordinal variable)

# educ_ordinal
data <- data %>%
  mutate(educ_ordinal = ifelse(educ == "Less than High School", 1,
                               ifelse(educ == "High School / GED", 2,
                                      ifelse(educ == "Some College", 3,
                                             ifelse(educ == "2-year College Degree", 4,
                                                    ifelse(educ == "4-year College Degree", 5,
                                                           ifelse(educ == "Masters Degree", 6,
                                                                  ifelse(educ == "Doctoral Degree", 7,
                                                                         ifelse(educ == "Professional Degree (JD, MD)", 8, NA)))))))))
```



```{r}
# Treatment conditions

# Overqual condition (Capability)
data <- data %>%
  mutate(Overqual = ifelse(is.na(Profile_DO_high_overqual_profil), "Low", "High")) %>%
  mutate(Overqual = as.factor(Overqual))

data <- data %>%
  mutate(Commitment = ifelse(is.na(CommitmentManipulation_DO_highcommitment_HR), "Neutral", "High")) %>%
  mutate(Commitment = as.factor(Commitment))


# Check number of participants in each condition
table(data$Overqual, data$Commitment)

```

###### Nov 23, 2021 (EDITING)





```{r}
# overqual - high (condition1)

data_cleaning <- data_cleaning |>
  mutate(cond1_high_overqual = ifelse(is.na(Profile_DO_high_overqual_profil), 0, 1))

data_cleaning <- data_cleaning |>
  mutate(cond1_low_overqual = ifelse(is.na(Profile_DO_low_overqual_profile), 0, 1))

# commit - high (condition2)

data_cleaning <- data_cleaning |>
  mutate(cond2_high_commit = ifelse(is.na(CommitmentManipulation_DO_highcommitment_HR), 0, 1))

data_cleaning <- data_cleaning |>
  mutate(cond2_neutral_commit = ifelse(is.na(CommitmentManipulation_DO_neutralcommitment_HR), 0, 1))



```


```{r}
# clean data (first step)
data_brief <- data_cleaning |>
  select(c('offer_score', 'cond1_high_overqual', 'cond1_low_overqual', 'cond2_high_commit', 'cond2_neutral_commit', 'Profile_DO_high_overqual_profil', 'Profile_DO_low_overqual_profile', 'CommitmentManipulation_DO_highcommitment_HR', 'CommitmentManipulation_DO_neutralcommitment_HR'))

data_brief <- data_cleaning |>
  select(c('offer_score', 'cond1_high_overqual', 'cond1_low_overqual', 'cond2_high_commit', 'cond2_neutral_commit'))

```


#### Prepare data for analysis - create columns etc.

```{r}
#data_brief <- data_brief |>
#  mutate(cond1_high_overqual = factor(cond1_high_overqual, levels = c(0, 1), labels = c("Low", "High")))


# only for neutral commitment condition
data_neutral <- data_brief |>
  filter(cond2_high_commit == 0) |>
  select(c("offer_score", "cond1_high_overqual")) |>
  mutate(cond1_high_overqual = factor(cond1_high_overqual, levels = c(0, 1), labels = c("Low", "High")))
  

# only for high commitment condition
data_high <- data_brief |>
  filter(cond2_high_commit == 1) |>
  select(c("offer_score", "cond1_high_overqual")) |>
  mutate(cond1_high_overqual = factor(cond1_high_overqual, levels = c(0, 1), labels = c("Low", "High")))

```

### Descriptive statistics


#### Pilot B

```{r}
library(psych)
describe(data_brief)
```

```{r}
describe(data_neutral)
```


```{r}
describe(data_high)
```

```{r}
commit_labels <- c("Neutral Commitment", "High Commitment")
names(commit_labels) <- c("0", "1")

ggplot(data = data_brief, aes(x = cond1_high_overqual, y = offer_score, group = cond1_high_overqual, fill = cond1_high_overqual)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.08, alpha = .8) +
  guides(fill = "none") +
  scale_y_continuous(breaks = 1:7, limits = c(1, 7)) +
  theme(legend.position = c(0.9, 0.15),
        legend.direction = "vertical",
        legend.background = element_rect(fill = "transparent"),
        legend.title = element_blank(),
        axis.line = element_line(),
        panel.grid = element_blank(), 
        panel.background = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  facet_wrap(~cond2_high_commit, labeller = labeller(cond2_high_commit = commit_labels)) +
  ggtitle("Pilot B Results (pooled)") +
  labs(x = "Capability", y = "Likely to get an offer")

ggsave("/Users/jbyun/Dropbox/2021 Fall/PSYCH 251/galperin2020/data/data_boxplot.png")
```




### Confirmatory analysis (EDITING)

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

The main statistical model is going to be two t-tests, the same as that from original study. One t-test is to be conducted for Neutral commitment condition and the other t-test is going to be conducted for High commitment condition.


#### Pilot B

Below are the key analyses results from Pilot B.
\

```{r, echo = TRUE}
#neutral_t <- t.test(offer_score ~ cond1_high_overqual, data = data_neutral)
#neutral_t

# could not run the model because I do not have enough observations.
```

\

For the first t-test, I could not run the model because I did not have enough observations. This is due to small sample size and randomization. I expect this problem to be resolved itself when I get enough sample size for the study.

```{r}
high_t <- t.test(offer_score ~ cond1_high_overqual, data = data_high, paired = FALSE)
high_t
```

The above shows the results for the second t-test. (For high commitment group.)
\


```{r}
data_highcommit <- data %>%
  filter(Commitment == "High")

t.test(offer_score ~ Overqual, data = data_highcommit)

data_neutralcommit <- data %>%
  filter(Commitment == "Neutral")
t.test(offer_score ~ Overqual, data = data_neutralcommit)

```




### Exploratory analyses

```
Planning to conduct ANOVA or ANCOVA here
```
Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
